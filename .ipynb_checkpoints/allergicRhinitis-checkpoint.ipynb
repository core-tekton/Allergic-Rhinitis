{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import timeit\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbda915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO]: Trying to Read the images\")\n",
    "#  Configure the Image Location\n",
    "# 이미지 위치 구성하기\n",
    "imagePaths = list(paths.list_images(r'C:\\Users\\cvpr\\Documents\\Bishal\\Allergic Rhinitis\\Dataset\\non_rotate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2395bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2ecd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffle(imagePaths)\n",
    "imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(\"Dataset/rotate\"))\n",
    "len(imagePaths)\n",
    "imagePaths[0].split(os.path.sep)[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dd74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c494aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbfc861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize data and labels\n",
    "# 데이터 및 레이블 초기화\n",
    "data = []\n",
    "labels = []\n",
    "dirList= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8207bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting data and labels\n",
    "for imagePath in imagePaths:\n",
    "    # Extract the class label from file name and append to labels\n",
    "    # 파일 이름에서 클래스 레이블을 추출하고 레이블에 추가함\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    # Load the image, swap color channels, and resize it to be a fixed 224x224 pixels while ignoring the aspect ratio\n",
    "    # 이미지를 로드하고, 컬러 채널을 스왑하고, 가로 세로 비율을 무시하고 고정 224x224 픽셀로 크기를 조정함\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    # Append to data\n",
    "    # 데이터에 추가\n",
    "    data.append(image)\n",
    "\n",
    "# Convert the data and labels to NumPy arrays while scaling the pixel intensities to the range [0,1]\n",
    "# 픽셀 강도를 [0,1] 범위로 조정하면서 데이터와 레이블을 NumPy 배열로 변환\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1334c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e520d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4120256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f8028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211c77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform the one-hot encoding on the labels\n",
    "# 레이블에 대해 원핫 인코딩 수행\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5db2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training data augmentation\n",
    "# 교육 데이터 억멘테이션 초기화\n",
    "trainAug = ImageDataGenerator(rotation_range=40, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2,\n",
    "\t\tshear_range=0.15,fill_mode=\"nearest\", horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29189ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into training and testing splits using 80% of the training data and the remaining 20% for testing\n",
    "# 교육 데이터의 80%, 테스트에 20%를 사용하여 데이터를 교육 및 테스트 분할로 분할\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f69234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network, ensuring the Head-FC layer sets are left off\n",
    "# Head-FC 레이어 세트가 포함되지 않도록 네트워크를 로드한다\n",
    "baseModel = Xception(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afca810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the head model that will be placed on the top of the base model\n",
    "# 보디 모델의 맨 위에 배치할 헤드 모델 구성\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4,4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(3, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46169eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the Head-FC model on top of the Base model - This become the actual model that we will train\n",
    "# Head-FC 모델을 보디 모델 위에 배치한다. 이것이 우리가 교육할 실제 모델이 될 것이다.\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5790d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the basemodel layers will not be trained and only head model will be trained.\n",
    "# 보디 모델 레이어가 훈련되지 않고 헤드 모델만 훈련되는지 확인한다.\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f5a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bfbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyper-parameters\n",
    "# 하이퍼 파라미터 설정\n",
    "# INIT_LR = 1e-3\n",
    "INIT_LR = 0.001\n",
    "EPOCHS = 100\n",
    "BS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "# 모델 컴파일\n",
    "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Network Model\n",
    "# 모델 교육\n",
    "print(\"[INFO] Model Training\")\n",
    "start = timeit.default_timer()\n",
    "H = model.fit(\n",
    "        trainAug.flow(trainX, trainY, batch_size=BS),\n",
    "        steps_per_epoch=len(trainX) // BS,\n",
    "        validation_data=(testX, testY),\n",
    "        validation_steps=len(testX) // BS,\n",
    "        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287ab9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop = timeit.default_timer()\n",
    "print('Total Training Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689ae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd52999",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54faf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "# 테스트 세트에서 예측한다\n",
    "print(\"Making Predictions on the Test Set\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "preds = predIdxs\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62354ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predIdxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix and derrive raw, accuracy, sensitivity, specificity from it\n",
    "# 혼란 매트릭스\n",
    "cm= confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0,0] + cm[1,1] + cm[2,2]) / total\n",
    "\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
    "# 혼란 매트릭스 보기\n",
    "print(\"Confusion Matrix and its Derrivatives\")\n",
    "print(cm)\n",
    "print(\"acc: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b099c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "H.history[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "# 플롯 그래프\n",
    "print(\"Final Plot Generated.\")\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Allergic Rhinitis XceptNet-Aligned-all-e-3-0.5\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.savefig(\"[iter-3] [XCEPTN] plot,rotate-1e3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e9f07",
   "metadata": {},
   "source": [
    "model.output_shape # model summary representation\n",
    "model.summary() # model configuration\n",
    "model.get_config() # list all weight tensors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834c81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfefc33",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa59268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab71213",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09990552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ece74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ARhinitisModel\", save_format=\"h5\")\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977cc16",
   "metadata": {},
   "source": [
    "print(\"[INFO] saving Allergic Rhinitis detector model...\")\n",
    "model.save(\"ARhinitisModel\", save_format=\"h5\")\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95b803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb6c66bd",
   "metadata": {},
   "source": [
    "decoded = imagenet_utils.decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ae622",
   "metadata": {},
   "source": [
    "gradCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f4709",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548629b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f245932",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testX[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f49c08",
   "metadata": {},
   "source": [
    "preprocess_input = keras.applications.xception.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e85b4",
   "metadata": {},
   "source": [
    "for i in testX:\n",
    "    image = np.expand_dims(i, axis=0)\n",
    "    image = imagenet_utils.preprocess_input(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f18fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb913fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timg in testX:\n",
    "    timg = np.expand_dims(timg, axis=0)\n",
    "    print(timg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522594f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = testX[12]\n",
    "testImage = np.expand_dims(testImage, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = np.uint8(255 * testImage)\n",
    "testImage = []\n",
    "testImage.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testImage[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a259da3",
   "metadata": {},
   "source": [
    "To save img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img101 = keras.preprocessing.image.array_to_img(testImage[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "img101.save(\"temp.jpg\")\n",
    "display(Image(\"temp.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523237af",
   "metadata": {},
   "source": [
    "Select Last Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9351228",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = \"block14_sepconv2_act\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96169a85",
   "metadata": {},
   "source": [
    "Get Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74739409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "#img_array = testX[:1]\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "#preds = model.predict(testImage)\n",
    "#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "print(preds)\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(testImage, model, last_conv_layer_name)\n",
    "print(heatmap.shape)\n",
    "\n",
    "# Display heatmap\n",
    "plt.imshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106802d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4, img_=None):\n",
    "    # Load the original image\n",
    "    #img = keras.preprocessing.image.load_img(img_path)\n",
    "    #img = keras.preprocessing.image.img_to_array(img)\n",
    "    img = img_\n",
    "   \n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(\"temp.jpg\", heatmap, img_=testImage[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1880c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed5271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7e9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd98da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0e356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29229dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "#img_array = testX[:1]\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(testImg)\n",
    "#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "print(preds)\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(testImg, model, last_conv_layer_name)\n",
    "print(heatmap.shape)\n",
    "\n",
    "# Display heatmap\n",
    "plt.imshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4795a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4, img_=None):\n",
    "    # Load the original image\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "    img = img_\n",
    "   \n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(\"temp.jpg\", heatmap, img_=testImg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = \"gradMap.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath.split(\".\")[0]+\"Nis\"+outpath.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c1921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ccb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradCam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = imagePaths[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = gradCam2.getHeatMap(img_, model, \"block14_sepconv2_act\",imageType=\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59567db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradCam2.saveGradCam(img_, heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405910ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath = \"gradCam.jpg\"\n",
    "outPath = outPath.split(\".\")[0] + \"-\" + datetime.now().strftime('%H-%M-%S') + \".\" + outPath.split(\".\")[1]\n",
    "outPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514790c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a91d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
